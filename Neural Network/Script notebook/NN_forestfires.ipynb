{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f977ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fd0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\Assignments\\\\forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22932e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cace295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb68e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e327dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#df['size_category'].value_counts().plot.pie()\n",
    "#plt.show()\n",
    "#print(df['size_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0650889",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4f2b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  FFMC  DMC   DC  ISI  temp  RH  wind  rain  ...  monthdec  \\\n",
       "0        7    0    28   37   41   29    12  34    14     0  ...         0   \n",
       "1       10    5    56   49  144   42    85  16     1     0  ...         0   \n",
       "2       10    2    56   56  156   42    55  16     2     0  ...         0   \n",
       "3        7    0    67   48   33   64    13  72     8     1  ...         0   \n",
       "4        7    3    46   66   46   68    30  73     3     0  ...         0   \n",
       "..     ...  ...   ...  ...  ...  ...   ...  ..   ...   ...  ...       ...   \n",
       "512      1    3     9   71  141    7   172  15     5     0  ...         0   \n",
       "513      1    3     9   71  141    7   123  54    12     0  ...         0   \n",
       "514      1    3     9   71  141    7   116  53    14     0  ...         0   \n",
       "515      1    2    92  168  122   80   156  25     8     0  ...         0   \n",
       "516      9    5     7    2   48    4    34  14     9     0  ...         0   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  \n",
       "0           0         0  \n",
       "1           1         0  \n",
       "2           1         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "512         0         0  \n",
       "513         0         0  \n",
       "514         0         0  \n",
       "515         0         0  \n",
       "516         0         0  \n",
       "\n",
       "[517 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_x=LabelEncoder()\n",
    "x=x.apply(LabelEncoder().fit_transform)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e1aa8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size_category\n",
       "0                1\n",
       "1                1\n",
       "2                1\n",
       "3                1\n",
       "4                1\n",
       "..             ...\n",
       "512              0\n",
       "513              0\n",
       "514              0\n",
       "515              1\n",
       "516              1\n",
       "\n",
       "[517 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y)\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = y.apply(LabelEncoder().fit_transform)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f0f8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a96f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15cfee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6cf0c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 0.6817 - accuracy: 0.8988 - val_loss: 0.6538 - val_accuracy: 0.8655\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.9451 - val_loss: 0.3672 - val_accuracy: 0.9357\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2215 - accuracy: 0.9538 - val_loss: 0.2411 - val_accuracy: 0.8713\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9682 - val_loss: 0.2136 - val_accuracy: 0.8830\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9653 - val_loss: 0.2210 - val_accuracy: 0.8830\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9769 - val_loss: 0.1527 - val_accuracy: 0.9474\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9624 - val_loss: 0.1376 - val_accuracy: 0.9532\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9769 - val_loss: 0.1553 - val_accuracy: 0.9415\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9798 - val_loss: 0.1228 - val_accuracy: 0.9532\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9682 - val_loss: 0.1683 - val_accuracy: 0.9357\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9682 - val_loss: 0.1219 - val_accuracy: 0.9532\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9798 - val_loss: 0.1456 - val_accuracy: 0.9357\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9769 - val_loss: 0.1516 - val_accuracy: 0.9298\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9769 - val_loss: 0.2325 - val_accuracy: 0.8889\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 0.1237 - val_accuracy: 0.9474\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9769 - val_loss: 0.1191 - val_accuracy: 0.9474\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9827 - val_loss: 0.1015 - val_accuracy: 0.9415\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.0998 - val_accuracy: 0.9415\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9798 - val_loss: 0.1230 - val_accuracy: 0.9415\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9827 - val_loss: 0.0981 - val_accuracy: 0.9532\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9855 - val_loss: 0.1447 - val_accuracy: 0.9298\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9884 - val_loss: 0.1732 - val_accuracy: 0.9298\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9798 - val_loss: 0.1041 - val_accuracy: 0.9474\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 0.1423 - val_accuracy: 0.9474\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9827 - val_loss: 0.1382 - val_accuracy: 0.9474\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9827 - val_loss: 0.1091 - val_accuracy: 0.9474\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9798 - val_loss: 0.0999 - val_accuracy: 0.9415\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9913 - val_loss: 0.1181 - val_accuracy: 0.9532\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9827 - val_loss: 0.1056 - val_accuracy: 0.9415\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9798 - val_loss: 0.0990 - val_accuracy: 0.9357\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9884 - val_loss: 0.1108 - val_accuracy: 0.9474\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9913 - val_loss: 0.1078 - val_accuracy: 0.9415\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9884 - val_loss: 0.1395 - val_accuracy: 0.9474\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.1239 - val_accuracy: 0.9474\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9884 - val_loss: 0.2247 - val_accuracy: 0.9298\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9827 - val_loss: 0.1238 - val_accuracy: 0.9474\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.1315 - val_accuracy: 0.9474\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 0.2258 - val_accuracy: 0.9298\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 0.1208 - val_accuracy: 0.9474\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9798 - val_loss: 0.1344 - val_accuracy: 0.9415\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.1477 - val_accuracy: 0.9474\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.1449 - val_accuracy: 0.9474\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9884 - val_loss: 0.1460 - val_accuracy: 0.9357\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9884 - val_loss: 0.2860 - val_accuracy: 0.9298\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9884 - val_loss: 0.2450 - val_accuracy: 0.9357\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.1562 - val_accuracy: 0.9474\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.1440 - val_accuracy: 0.9357\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9913 - val_loss: 0.2066 - val_accuracy: 0.9415\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.1450 - val_accuracy: 0.9357\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9827 - val_loss: 0.1530 - val_accuracy: 0.9474\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9798 - val_loss: 0.1718 - val_accuracy: 0.9474\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.1543 - val_accuracy: 0.9415\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.1858 - val_accuracy: 0.9474\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9884 - val_loss: 0.1566 - val_accuracy: 0.9357\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.2074 - val_accuracy: 0.9474\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9913 - val_loss: 0.1843 - val_accuracy: 0.9474\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9913 - val_loss: 0.1747 - val_accuracy: 0.9474\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.1847 - val_accuracy: 0.9474\n",
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9913 - val_loss: 0.1713 - val_accuracy: 0.9474\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.2141 - val_accuracy: 0.9415\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.2414 - val_accuracy: 0.9298\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.2260 - val_accuracy: 0.9415\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.1650 - val_accuracy: 0.9357\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.3350 - val_accuracy: 0.9357\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 0.2436 - val_accuracy: 0.9298\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.3230 - val_accuracy: 0.9357\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.3715 - val_accuracy: 0.9298\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.2537 - val_accuracy: 0.9298\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9942 - val_loss: 0.4172 - val_accuracy: 0.9181\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9913 - val_loss: 0.2805 - val_accuracy: 0.9357\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.2374 - val_accuracy: 0.9415\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.1937 - val_accuracy: 0.9474\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.2636 - val_accuracy: 0.9357\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9913 - val_loss: 0.2410 - val_accuracy: 0.9474\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.2504 - val_accuracy: 0.9474\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9913 - val_loss: 0.2786 - val_accuracy: 0.9357\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.4205 - val_accuracy: 0.9123\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9884 - val_loss: 0.2201 - val_accuracy: 0.9474\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.1993 - val_accuracy: 0.9474\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9884 - val_loss: 0.2660 - val_accuracy: 0.9357\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9942 - val_loss: 0.2266 - val_accuracy: 0.9474\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.1812 - val_accuracy: 0.9357\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.2639 - val_accuracy: 0.9357\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9971 - val_loss: 0.3402 - val_accuracy: 0.9357\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9884 - val_loss: 0.3746 - val_accuracy: 0.9357\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.1887 - val_accuracy: 0.9357\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9855 - val_loss: 0.1842 - val_accuracy: 0.9240\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9884 - val_loss: 0.2719 - val_accuracy: 0.9357\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.2955 - val_accuracy: 0.9298\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9913 - val_loss: 0.2545 - val_accuracy: 0.9474\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9884 - val_loss: 0.2164 - val_accuracy: 0.9474\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.3499 - val_accuracy: 0.9357\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9884 - val_loss: 0.2755 - val_accuracy: 0.9357\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9884 - val_loss: 0.2371 - val_accuracy: 0.9474\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9942 - val_loss: 0.2585 - val_accuracy: 0.9474\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.2527 - val_accuracy: 0.9474\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.2753 - val_accuracy: 0.9357\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.2026 - val_accuracy: 0.9357\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9971 - val_loss: 0.3927 - val_accuracy: 0.9298\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9855 - val_loss: 0.2672 - val_accuracy: 0.9357\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9913 - val_loss: 0.2477 - val_accuracy: 0.9474\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.2299 - val_accuracy: 0.9474\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9913 - val_loss: 0.2973 - val_accuracy: 0.9357\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.3247 - val_accuracy: 0.9298\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.3093 - val_accuracy: 0.9298\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9855 - val_loss: 0.2116 - val_accuracy: 0.9415\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.2339 - val_accuracy: 0.9474\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.3332 - val_accuracy: 0.9240\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.2810 - val_accuracy: 0.9357\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9855 - val_loss: 0.2616 - val_accuracy: 0.9415\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9884 - val_loss: 0.2909 - val_accuracy: 0.9357\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9855 - val_loss: 0.3578 - val_accuracy: 0.9357\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9884 - val_loss: 0.2181 - val_accuracy: 0.9474\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.2927 - val_accuracy: 0.9298\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9913 - val_loss: 0.2512 - val_accuracy: 0.9474\n",
      "Epoch 116/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.3622 - val_accuracy: 0.9298\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 0.2945 - val_accuracy: 0.9357\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.2753 - val_accuracy: 0.9357\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.2954 - val_accuracy: 0.9298\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.2850 - val_accuracy: 0.9357\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9913 - val_loss: 0.2470 - val_accuracy: 0.9474\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.3148 - val_accuracy: 0.9298\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9913 - val_loss: 0.2767 - val_accuracy: 0.9415\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9971 - val_loss: 0.3385 - val_accuracy: 0.9240\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.2479 - val_accuracy: 0.9474\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.2957 - val_accuracy: 0.9357\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9884 - val_loss: 0.2553 - val_accuracy: 0.9474\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9942 - val_loss: 0.3804 - val_accuracy: 0.9298\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 0.3172 - val_accuracy: 0.9240\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.2395 - val_accuracy: 0.9415\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 0.3324 - val_accuracy: 0.9298\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.3141 - val_accuracy: 0.9298\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.3048 - val_accuracy: 0.9357\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9913 - val_loss: 0.2445 - val_accuracy: 0.9474\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.3830 - val_accuracy: 0.9298\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9913 - val_loss: 0.2699 - val_accuracy: 0.9474\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.3144 - val_accuracy: 0.9357\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.2657 - val_accuracy: 0.9474\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.2648 - val_accuracy: 0.9474\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9942 - val_loss: 0.3976 - val_accuracy: 0.9298\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.2547 - val_accuracy: 0.9474\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.2840 - val_accuracy: 0.9415\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.2488 - val_accuracy: 0.9474\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9855 - val_loss: 0.2780 - val_accuracy: 0.9474\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9913 - val_loss: 0.3056 - val_accuracy: 0.9357\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9942 - val_loss: 0.2661 - val_accuracy: 0.9474\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.3393 - val_accuracy: 0.9240\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9913 - val_loss: 0.2900 - val_accuracy: 0.9415\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.3448 - val_accuracy: 0.9240\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9855 - val_loss: 0.4331 - val_accuracy: 0.9240\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x, y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "656ea4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9691\n",
      "accuracy: 96.91%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821a3368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74dfc402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9698f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.874674e-17</td>\n",
       "      <td>5.110891e-17</td>\n",
       "      <td>-9.019220e-17</td>\n",
       "      <td>2.594099e-16</td>\n",
       "      <td>6.442300e-17</td>\n",
       "      <td>-8.718579e-17</td>\n",
       "      <td>-7.816657e-17</td>\n",
       "      <td>6.485249e-17</td>\n",
       "      <td>4.724353e-18</td>\n",
       "      <td>-4.790924e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.317959e+00</td>\n",
       "      <td>-1.423121e+00</td>\n",
       "      <td>-2.755520e+00</td>\n",
       "      <td>-2.134531e+00</td>\n",
       "      <td>-2.119754e+00</td>\n",
       "      <td>-2.133725e+00</td>\n",
       "      <td>-2.036890e+00</td>\n",
       "      <td>-1.713964e+00</td>\n",
       "      <td>-2.004018e+00</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.089076e+00</td>\n",
       "      <td>-9.031536e-01</td>\n",
       "      <td>-5.025653e-01</td>\n",
       "      <td>-8.010724e-01</td>\n",
       "      <td>-7.605602e-01</td>\n",
       "      <td>-6.928003e-01</td>\n",
       "      <td>-7.181571e-01</td>\n",
       "      <td>-7.060079e-01</td>\n",
       "      <td>-7.499909e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.533922e-02</td>\n",
       "      <td>1.367805e-01</td>\n",
       "      <td>1.039993e-01</td>\n",
       "      <td>1.234588e-01</td>\n",
       "      <td>1.959092e-01</td>\n",
       "      <td>-4.438437e-02</td>\n",
       "      <td>4.755898e-02</td>\n",
       "      <td>-1.390326e-01</td>\n",
       "      <td>2.425585e-03</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>6.567476e-01</td>\n",
       "      <td>6.672378e-01</td>\n",
       "      <td>8.168572e-01</td>\n",
       "      <td>7.999952e-01</td>\n",
       "      <td>6.400547e-01</td>\n",
       "      <td>7.494654e-01</td>\n",
       "      <td>5.539372e-01</td>\n",
       "      <td>5.040366e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>1.696682e+00</td>\n",
       "      <td>1.793715e+00</td>\n",
       "      <td>1.670271e+00</td>\n",
       "      <td>1.538322e+00</td>\n",
       "      <td>2.117002e+00</td>\n",
       "      <td>2.025659e+00</td>\n",
       "      <td>2.947833e+00</td>\n",
       "      <td>3.012092e+00</td>\n",
       "      <td>1.354679e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -4.874674e-17  5.110891e-17 -9.019220e-17  2.594099e-16  6.442300e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.317959e+00 -1.423121e+00 -2.755520e+00 -2.134531e+00 -2.119754e+00   \n",
       "25%   -1.089076e+00 -9.031536e-01 -5.025653e-01 -8.010724e-01 -7.605602e-01   \n",
       "50%    5.533922e-02  1.367805e-01  1.039993e-01  1.234588e-01  1.959092e-01   \n",
       "75%    1.199754e+00  6.567476e-01  6.672378e-01  8.168572e-01  7.999952e-01   \n",
       "max    1.199754e+00  1.696682e+00  1.793715e+00  1.670271e+00  1.538322e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -8.718579e-17 -7.816657e-17  6.485249e-17  4.724353e-18 -4.790924e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -2.133725e+00 -2.036890e+00 -1.713964e+00 -2.004018e+00 -1.100649e-01   \n",
       "25%   -6.928003e-01 -7.181571e-01 -7.060079e-01 -7.499909e-01 -1.100649e-01   \n",
       "50%   -4.438437e-02  4.755898e-02 -1.390326e-01  2.425585e-03 -1.100649e-01   \n",
       "75%    6.400547e-01  7.494654e-01  5.539372e-01  5.040366e-01 -1.100649e-01   \n",
       "max    2.117002e+00  2.025659e+00  2.947833e+00  3.012092e+00  1.354679e+01   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 29  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)\n",
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc169905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yogasree\\AppData\\Local\\Temp\\ipykernel_22812\\1787105156.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
      "C:\\Users\\Yogasree\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=1.000 total time=   2.4s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.962 total time=   1.9s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.971 total time=   1.9s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.913 total time=   1.9s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.922 total time=   1.9s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=1.000 total time=   4.9s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.933 total time=   4.1s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.981 total time=   4.3s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.961 total time=   4.2s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.942 total time=   3.9s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=1.000 total time=   7.5s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.952 total time=   7.3s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.981 total time=   6.9s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.942 total time=   8.2s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.942 total time=   8.5s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.923 total time=   1.6s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.971 total time=   1.0s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.951 total time=   1.0s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.913 total time=   1.0s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.971 total time=   2.3s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.951 total time=   2.3s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.951 total time=   2.1s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.932 total time=   2.2s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   3.7s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.981 total time=   3.6s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.981 total time=   4.3s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.951 total time=   4.1s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.893 total time=   4.1s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.952 total time=   0.9s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.874 total time=   1.2s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x0000029EFDCEE040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.942 total time=   0.9s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000029EFB0BBCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.903 total time=   0.8s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.923 total time=   1.8s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.981 total time=   1.6s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.932 total time=   1.9s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.922 total time=   1.5s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=1.000 total time=   2.4s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.962 total time=   2.4s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.951 total time=   2.4s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.961 total time=   2.6s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.913 total time=   2.5s\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a79f474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9632374882698059, using {'batch_size': 10, 'epochs': 50}\n",
      "0.9534727334976196,0.03216002543762797 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9632374882698059,0.024704066979163684 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9632001399993897,0.023255008828743613 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.9516056776046753,0.03177092184407792 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9612210631370545,0.022998996115583786 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9612023830413818,0.037369753065260775 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.9340739250183105,0.043195689410228735 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.9516056776046753,0.032358862200512026 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.9573562383651734,0.027880119063319796 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "268a2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffd7292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yogasree\\AppData\\Local\\Temp\\ipykernel_22812\\3207423715.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.798 total time=   1.1s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.971 total time=   1.0s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.913 total time=   1.0s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.922 total time=   1.3s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.942 total time=   0.9s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.981 total time=   0.9s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.932 total time=   0.8s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.932 total time=   1.2s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.709 total time=   1.1s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.699 total time=   1.3s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.981 total time=   1.0s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.971 total time=   1.0s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.951 total time=   1.0s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.923 total time=   1.0s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.971 total time=   1.0s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.932 total time=   1.0s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.903 total time=   1.0s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.670 total time=   1.1s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.913 total time=   1.1s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.981 total time=   1.0s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.951 total time=   1.0s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.893 total time=   1.0s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.913 total time=   1.0s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.981 total time=   1.1s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.961 total time=   1.0s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.874 total time=   1.0s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94d0350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9495705723762512, using {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.7401979088783264,0.15673974414954747 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.9495705723762512,0.03217903744899643 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.918932044506073,0.08860520125439188 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7364077687263488,0.15285944434968482 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.9204256892204284,0.1118013858630472 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.9457804322242737,0.03496102763857248 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7597087383270263,0.1232856808208471 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.9477408528327942,0.03993182406501588 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.9457991123199463,0.04607664161725869 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c48f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "402dd38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yogasree\\AppData\\Local\\Temp\\ipykernel_22812\\2157490907.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.699 total time=   1.1s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   1.3s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.680 total time=   1.1s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.856 total time=   1.0s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.760 total time=   1.3s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.680 total time=   1.1s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.699 total time=   1.1s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.981 total time=   1.1s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.798 total time=   1.4s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.767 total time=   1.1s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.825 total time=   1.0s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.786 total time=   1.0s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=0.990 total time=   1.0s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.798 total time=   1.3s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.767 total time=   1.0s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.806 total time=   1.1s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.845 total time=   1.1s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.524 total time=   1.0s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.990 total time=   1.0s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.798 total time=   1.4s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.757 total time=   1.0s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.845 total time=   0.9s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.854 total time=   1.0s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.990 total time=   1.0s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.827 total time=   1.1s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.767 total time=   1.4s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.883 total time=   1.1s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.854 total time=   1.0s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.524 total time=   1.5s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.699 total time=   1.1s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60a42906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.864432418346405, using {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.5305825233459472,0.2757845556417363 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7517363667488098,0.162590161682125 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7325055956840515,0.15464018573921784 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.8314973831176757,0.076983589036074 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.8411874651908875,0.07859526845679017 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.8489544510841369,0.07879428845800032 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.864432418346405,0.073797750794808 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "888eb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 30,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91399ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yogasree\\AppData\\Local\\Temp\\ipykernel_22812\\1166029089.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.990 total time=   1.0s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.660 total time=   1.3s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.680 total time=   0.9s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.689 total time=   0.9s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.631 total time=   1.0s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.786 total time=   1.1s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.728 total time=   1.0s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.650 total time=   1.0s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.748 total time=   1.0s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.718 total time=   1.1s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.981 total time=   1.0s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.788 total time=   1.0s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.728 total time=   1.2s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.825 total time=   1.0s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.835 total time=   0.9s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.817 total time=   1.0s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.767 total time=   1.2s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.874 total time=   1.0s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.806 total time=   1.0s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.808 total time=   1.0s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.796 total time=   1.2s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.854 total time=   0.9s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.845 total time=   1.0s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.808 total time=   1.0s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.757 total time=   1.2s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.903 total time=   1.0s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.874 total time=   1.1s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.856 total time=   1.0s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   1.0s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   1.3s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.893 total time=   1.0s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.846 total time=   1.0s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.883 total time=   1.0s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.932 total time=   1.2s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.903 total time=   1.0s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6b30447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9129200935363769, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.7539021611213684,0.12199202300426415 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7791262030601501,0.12182436065728823 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7733009815216064,0.118903299492602 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.8315160512924195,0.08350424540323734 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.8527819275856018,0.08116391088252023 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.860567593574524,0.07305149031077991 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.8683345675468445,0.0831521621863036 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.8993091702461242,0.05171937788516113 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9129200935363769,0.051714879979820425 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be5c8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d0c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yogasree\\AppData\\Local\\Temp\\ipykernel_22812\\1196441048.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step\n",
      "0.9303675048355899\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9083e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
